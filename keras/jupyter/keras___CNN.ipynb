{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# keras CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# config = tf.ConfigProto(allow_soft_placement=True)\n",
    "# config.gpu_options.allocator_type = 'BFC'\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.40\n",
    "# config.gpu_options.allow_growth=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28)\n",
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "\n",
      "(60000, 1, 28, 28)\n",
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# X shape (60,000 28x28), y shape (10,000, )\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# normalize 归一化\n",
    "# 注意：这里如果不归一化，效果特别差\n",
    "X_train = X_train.reshape((-1, 1, 28, 28))/255.\n",
    "X_test = X_test.reshape((-1, 1, 28, 28))/255.\n",
    "\n",
    "# one-hot 编码\n",
    "y_train = np_utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "print(X_train[1].shape)\n",
    "print(y_train[0])\n",
    "\n",
    "print()\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# conv layer 1 output shape(32, 28, 28)\n",
    "model.add(\n",
    "    Convolution2D(\n",
    "        filters=32,     # number of filter, 滤波器的个数（卷积核）\n",
    "        kernel_size=5,  # number of row， 滤波器的大小\n",
    "        strides=1,\n",
    "        padding='same',  # padding method\n",
    "        batch_input_shape=(None, 1, 28, 28),  # picture height & width\n",
    "        data_format='channels_first',)\n",
    ")\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# poolint layer 1(max pooling output shape(64, 7, 7))\n",
    "model.add(\n",
    "    MaxPooling2D(\n",
    "        pool_size=2, \n",
    "        strides=2,\n",
    "        padding='same',  # padding method\n",
    "        data_format='channels_first',)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv layer 2 output shape(64, 14, 14)\n",
    "model.add(\n",
    "    Convolution2D(\n",
    "        filters=64,  # number of filter, 滤波器的个数（卷积核）\n",
    "        kernel_size=5,  # number of row， 滤波器的大小\n",
    "        strides=1,\n",
    "        padding='same',  # padding method\n",
    "        data_format='channels_first',\n",
    "))\n",
    "\n",
    "model.add(Activation('relu'))\n",
    "model.add(\n",
    "    MaxPooling2D(\n",
    "        pool_size=2, \n",
    "        strides=2, \n",
    "        padding='same', \n",
    "        data_format='channels_first',)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully conneted layer 1 input shape(64*7*&7)=(3136), output shape(1024)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# fully conneted layer 2 to shape(10) for 10 classes\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another  to define your optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=1e-4)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ----------------------\n",
      "WARNING:tensorflow:From D:\\Miniconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 332s 6ms/step - loss: 0.2048 - acc: 0.9419\n",
      "Wall time: 5min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Training ----------------------')\n",
    "model.fit(X_train, y_train, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing ----------------------\n",
      "10000/10000 [==============================] - 25s 3ms/step\n",
      "\n",
      "\n",
      "test loss:\t 0.20426653486080468\n",
      "test accuracy:\t 0.9374\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Testing ----------------------')\n",
    "\n",
    "# evaluate the model with the metrics we defined earlier[accuracy]\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print('\\n')\n",
    "print('test loss:\\t', loss)\n",
    "print('test accuracy:\\t', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验结果说明\n",
    "- 训练时候的batch_size设置为32比64要好\n",
    "\n",
    "> batch_size=32: 0.9753\n",
    "\n",
    "> batch_size=64: 0.9686\n",
    "\n",
    "- 数据预处理时候，一定要归一化。对实验结果影响超级大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 模型结构输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='../pic/cnn_model.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用tensorboard\n",
    "tensorboard --logdir=.\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'andyni-test-cnn-1561017485'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"andyni-test-cnn-%d\" % int(time.time())\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.TensorBoard at 0x10c0fd30>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard = TensorBoard(\n",
    "    log_dir='../log/%s' % model_name, \n",
    "    \n",
    "    \n",
    "#     batch_size=32,\n",
    "#     update_freq=20,\n",
    "#     histogram_freq=1, \n",
    "#     write_grads=1,\n",
    "#     write_images=1, \n",
    "#     write_graph=True, \n",
    "\n",
    "#     histogram_freq=1, \n",
    "    batch_size=32,\n",
    "    update_freq=50,\n",
    "    write_graph=True, \n",
    "    write_grads=True, \n",
    "    write_images=True,\n",
    "    embeddings_freq=0, \n",
    "    embeddings_layer_names=None,\n",
    "    embeddings_metadata=None,\n",
    "    embeddings_data=None, \n",
    ")\n",
    "\n",
    "tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 1, 28, 28) (5000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_train[:5000, :].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ----------------------\n",
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/5\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 0.0026 - val_acc: 1.0000\n",
      "Epoch 2/5\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 3/5\n",
      "80/80 [==============================] - 1s 10ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 4/5\n",
      "80/80 [==============================] - 1s 12ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 5/5\n",
      "80/80 [==============================] - 1s 9ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "print('Training ----------------------')\n",
    "\n",
    "history_data = model.fit(\n",
    "    X_train[:100, :], y_train[:100, :], \n",
    "#     validation_data=(X_test[:500], y_test[:500]),\n",
    "    epochs=5,\n",
    "    batch_size=32, \n",
    "    validation_split=0.2, \n",
    "#     shuffle=True, \n",
    "#     callbacks=[tensorboard],\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 669 samples, validate on 331 samples\n",
      "Epoch 1/1\n",
      "669/669 [==============================] - 18s 26ms/step - loss: 0.0212 - acc: 1.0000 - val_loss: 0.1052 - val_acc: 0.9698\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train[:1000, :], y_train[:1000, :], \n",
    "    validation_split=0.33, \n",
    "    epochs=1, \n",
    "    batch_size=10, \n",
    "    verbose=1,\n",
    ") # list all data in history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练过程数据 - keras.callbacks.History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.callbacks.History"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(history_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_data.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'epochs': 5,\n",
       " 'steps': None,\n",
       " 'samples': 80,\n",
       " 'verbose': 1,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss', 'acc', 'val_loss', 'val_acc']}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_data.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [0.0026031925808638334,\n",
       "  0.002168559469282627,\n",
       "  0.0019702825229614973,\n",
       "  0.0019085370004177094,\n",
       "  0.0019146029371768236],\n",
       " 'val_acc': [1.0, 1.0, 1.0, 1.0, 1.0],\n",
       " 'loss': [0.01024192590266466,\n",
       "  0.00938895419239998,\n",
       "  0.00823008194565773,\n",
       "  0.007289296155795455,\n",
       "  0.0066370277665555475],\n",
       " 'acc': [1.0, 1.0, 1.0, 1.0, 1.0]}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_data.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
